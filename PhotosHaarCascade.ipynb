{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b54521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64fc80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = Path(\"photo/images\")\n",
    "output_dir_haar = Path(\"face_detected_HaarCascade\")\n",
    "output_dir_haar.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cropped_dir_haar = Path(\"cropped_face_HaarCascade\")\n",
    "cropped_dir_haar.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f0e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haar Cascade pre-trained model from OpenCV\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "no_face_detected = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cbc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_faces_haar(img_path, scaleFactor=1.05, minNeighbors=4, minSize=(40, 40)):\n",
    "#     img = cv2.imread(str(img_path))\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     faces = face_cascade.detectMultiScale(\n",
    "#         gray,\n",
    "#         scaleFactor=scaleFactor,\n",
    "#         minNeighbors=minNeighbors,\n",
    "#         minSize=minSize\n",
    "#     )\n",
    "\n",
    "#     for idx, (x, y, w, h) in enumerate(faces, start=1):\n",
    "#         cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "#         # Crop and save each face\n",
    "#         face_crop = img[y:y+h, x:x+w]\n",
    "#         crop_name = f\"{img_path.stem}_face_{idx}.jpg\"\n",
    "#         cv2.imwrite(str(cropped_dir_haar / crop_name), face_crop)\n",
    "\n",
    "#     # Save image with rectangles\n",
    "#     output_path = output_dir_haar / img_path.name\n",
    "#     cv2.imwrite(str(output_path), img)\n",
    "\n",
    "#     print(f\"{img_path.name}: {len(faces)} face(s) detected and cropped (HaarCascade).\")\n",
    "\n",
    "def detect_faces_haar(img_path, scaleFactor=1.05, minNeighbors=4, minSize=(40, 40)):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scaleFactor,\n",
    "        minNeighbors=minNeighbors,\n",
    "        minSize=minSize\n",
    "    )\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        no_face_detected.append(img_path)\n",
    "    else:\n",
    "        for idx, (x, y, w, h) in enumerate(faces, start=1):\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            face_crop = img[y:y+h, x:x+w]\n",
    "            crop_name = f\"{img_path.stem}_face_{idx}.jpg\"\n",
    "            cv2.imwrite(str(cropped_dir_haar / crop_name), face_crop)\n",
    "\n",
    "    cv2.imwrite(str(output_dir_haar / img_path.name), img)\n",
    "    print(f\"HaarCascade processed: {img_path.name}, faces detected: {len(faces)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa62a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the images\n",
    "image_counter = 0\n",
    "max_images = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950b5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HaarCascade processed: 00.jpg, faces detected: 10\n",
      "HaarCascade processed: 01.jpg, faces detected: 5\n",
      "HaarCascade processed: 02.jpg, faces detected: 6\n",
      "HaarCascade processed: 03.jpg, faces detected: 3\n",
      "HaarCascade processed: 04.jpg, faces detected: 10\n",
      "HaarCascade processed: 05.jpg, faces detected: 4\n",
      "HaarCascade processed: 06.jpg, faces detected: 42\n",
      "HaarCascade processed: 07.jpg, faces detected: 101\n",
      "HaarCascade processed: 08.jpg, faces detected: 62\n",
      "HaarCascade processed: 09.jpg, faces detected: 4\n",
      "HaarCascade processed: 10.jpg, faces detected: 3\n",
      "HaarCascade processed: 11.jpg, faces detected: 6\n",
      "HaarCascade processed: 12.jpg, faces detected: 3\n",
      "HaarCascade processed: 13.jpg, faces detected: 5\n",
      "HaarCascade processed: 14.jpg, faces detected: 6\n",
      "HaarCascade processed: 15.jpg, faces detected: 6\n",
      "HaarCascade processed: 16.jpg, faces detected: 6\n",
      "HaarCascade processed: 17.jpg, faces detected: 12\n",
      "HaarCascade processed: 18.jpg, faces detected: 16\n",
      "HaarCascade processed: 19.jpg, faces detected: 10\n",
      "HaarCascade processed: 20.jpg, faces detected: 11\n",
      "HaarCascade processed: 21.jpg, faces detected: 7\n",
      "HaarCascade processed: 22.jpg, faces detected: 13\n",
      "HaarCascade processed: 23.jpg, faces detected: 12\n",
      "HaarCascade processed: 24.jpg, faces detected: 11\n"
     ]
    }
   ],
   "source": [
    "for folder in input_dir.iterdir():\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "    for img_path in folder.glob(\"*.jpg\"):\n",
    "        if image_counter >= max_images:\n",
    "            break\n",
    "        detect_faces_haar(img_path)\n",
    "        image_counter += 1\n",
    "    if image_counter >= max_images:\n",
    "        break\n",
    "\n",
    "# for folder in input_dir.iterdir():\n",
    "#     if not folder.is_dir():\n",
    "#         continue\n",
    "#     for img_path in folder.glob(\"*.jpg\"):\n",
    "#         detect_faces_haar(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ea2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total images without faces detected (HaarCascade): 0\n"
     ]
    }
   ],
   "source": [
    "# Show first 5 images without face\n",
    "print(f\"\\nTotal images without faces detected (HaarCascade): {len(no_face_detected)}\")\n",
    "\n",
    "for img_path in no_face_detected[:5]:\n",
    "    img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"No face detected: {img_path.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
