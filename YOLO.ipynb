{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5cb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import fitz\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# YOLO\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f85ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = Path(\"photo/images\")\n",
    "pdf_dir = Path(\"pdfs\")\n",
    "output_dir_pose = Path(\"face_detected_YOLO\")\n",
    "cropped_dir_pose = Path(\"cropped_faces_YOLO\")\n",
    "pdf_cropped_dir = Path(\"pdf_cropped_faces_YOLO\")\n",
    "\n",
    "output_dir_pose.mkdir(parents=True, exist_ok=True)\n",
    "cropped_dir_pose.mkdir(parents=True, exist_ok=True)\n",
    "pdf_cropped_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c585974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv5 Pose model\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model = YOLO('yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca93772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_yolo_pose(img, img_name, save_dir):\n",
    "    results = model(img)\n",
    "    \n",
    "    face_count = 0\n",
    "    for result in results:\n",
    "        # Obtener bounding boxes (person class = 0)\n",
    "        boxes = result.boxes.xyxy[result.boxes.cls == 0].cpu().numpy()\n",
    "        \n",
    "        for box in boxes:\n",
    "            xmin, ymin, xmax, ymax = map(int, box[:4])\n",
    "            face_crop = img[ymin:ymax, xmin:xmax]\n",
    "            face_count += 1\n",
    "            face_filename = save_dir / f\"{img_name}_face_{face_count}.jpg\"\n",
    "            cv2.imwrite(str(face_filename), cv2.cvtColor(face_crop, cv2.COLOR_RGB2BGR))\n",
    "            print(f\"Saved: {face_filename.name}\")\n",
    "    \n",
    "    # Save annotated image in output_dir_pose\n",
    "    for result in results:\n",
    "        annotated_img = result.plot()\n",
    "        annotated_path = output_dir_pose / f\"{img_name}_annotated.jpg\"\n",
    "        cv2.imwrite(str(annotated_path), cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Annotated image saved: {annotated_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    for folder in input_dir.iterdir():\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        for img_path in folder.glob(\"*.jpg\"):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            detect_faces_yolo_pose(img_rgb, img_path.stem, cropped_dir_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path, dpi=300):\n",
    "    pdf_document = fitz.open(str(pdf_path))\n",
    "    img_paths = []\n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        zoom = dpi / 72\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape((pix.height, pix.width, 3))\n",
    "        img_paths.append((img_array, page_num + 1))\n",
    "    return img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(max_images=25):\n",
    "    image_counter = 0\n",
    "    for folder in input_dir.iterdir():\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "        for img_path in folder.glob(\"*.jpg\"):\n",
    "            if image_counter >= max_images:\n",
    "                print(f\"Reached the max limit of {max_images} images.\")\n",
    "                return\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            detect_faces_yolo_pose(img_rgb, img_path.stem, cropped_dir_pose)\n",
    "            image_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(max_images=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs():\n",
    "    pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"Processing PDF: {pdf_file.name}\")\n",
    "        try:\n",
    "            pages = pdf_to_images(pdf_file)\n",
    "            for img_array, page_num in pages:\n",
    "                img_rgb = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "                img_name = f\"{pdf_file.stem}_page_{page_num}\"\n",
    "                detect_faces_yolo_pose(img_rgb, img_name, pdf_cropped_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file.name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be45647",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c7196",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b373bf",
   "metadata": {},
   "source": [
    "# YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b919ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Images\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from typing import List, Optional, Dict, Any\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# PDF's\n",
    "import fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e26a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection using YOLO with precision, efficiency, and portability considerations.\n",
    "class FaceDetector:\n",
    "    def __init__(self):\n",
    "        # Configuration\n",
    "        self.input_dir = Path(\"photo/images\")\n",
    "        self.output_dir = Path(\"face_detected_YOLO\")\n",
    "        self.cropped_dir = Path(\"cropped_faces_YOLO\")\n",
    "        self.no_face_detected: List[Path] = []\n",
    "\n",
    "        # Create directories\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.cropped_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "    # Detect faces using YOLO with timing metric\n",
    "    def detect_faces(self, img_path: Path, is_pdf: bool = False) -> Optional[int]:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            img = cv2.imread(str(img_path)) if isinstance(img_path, Path) else img_path\n",
    "            if img is None:\n",
    "                print(f\"Error reading image: {img_path}\")\n",
    "                return None\n",
    "\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detection\n",
    "            detect_start = time.time()\n",
    "            results = self.model(img_rgb)\n",
    "            detect_time = time.time() - detect_start\n",
    "\n",
    "            face_count = 0\n",
    "            for result in results:\n",
    "                boxes = result.boxes.xyxy[result.boxes.cls == 0].cpu().numpy()\n",
    "                face_count += len(boxes)\n",
    "                \n",
    "                for box in boxes:\n",
    "                    self._process_detection(img_rgb, img_path, box, face_count, is_pdf)\n",
    "\n",
    "            # Save annotated image if not PDF\n",
    "            if not is_pdf and isinstance(img_path, Path):\n",
    "                annotated_img = results[0].plot()\n",
    "                output_path = self.output_dir / img_path.name\n",
    "                cv2.imwrite(str(output_path), cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"YOLO: {getattr(img_path, 'name', 'PDF_page')} | \"\n",
    "                  f\"Faces: {face_count} | Detect: {detect_time:.3f}s | Total: {elapsed:.3f}s\")\n",
    "            \n",
    "            return face_count\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {getattr(img_path, 'name', 'PDF_page')}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # Process and save a single face detectio\n",
    "    def _process_detection(self, img: np.ndarray, img_path, box, idx: int, is_pdf: bool) -> None:\n",
    "        xmin, ymin, xmax, ymax = map(int, box[:4])\n",
    "        face_crop = img[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        crop_name = f\"{getattr(img_path, 'stem', 'PDF_page')}_face_{idx}.jpg\"\n",
    "        output_path = self.cropped_dir / crop_name\n",
    "        cv2.imwrite(str(output_path), cv2.cvtColor(face_crop, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Draw rectangle if not PDF\n",
    "        if not is_pdf:\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "\n",
    "    # Display sample images where no faces were detecte\n",
    "    def show_no_face_samples(self, sample_size: int = 3) -> None:\n",
    "        print(f\"\\nImages without faces detected: {len(self.no_face_detected)}\")\n",
    "        for img_path in self.no_face_detected[:sample_size]:\n",
    "            try:\n",
    "                img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"No face detected: {img_path.name}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error displaying {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ae1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFProcessor:\n",
    "    def __init__(self, face_detector: FaceDetector):\n",
    "        self.pdf_dir = Path('pdfs')\n",
    "        self.output_img_dir = Path('pdf_images_YOLO')\n",
    "        self.pdf_cropped_dir = Path('pdf_cropped_faces_YOLO')\n",
    "        self.detector = face_detector\n",
    "        self.detector.cropped_dir = self.pdf_cropped_dir\n",
    "\n",
    "        self.output_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.pdf_cropped_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Process all PDF files and return total processing tim\n",
    "    def process_pdfs(self) -> float:\n",
    "        pdf_files = list(self.pdf_dir.glob(\"*.pdf\"))\n",
    "        if not pdf_files:\n",
    "            print(\"No PDF files found\")\n",
    "            return 0.0\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"\\nStarting PDF processing...\")\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            self._process_pdf(pdf_file)\n",
    "            \n",
    "        return time.time() - start_time\n",
    "\n",
    "    # Process a single PDF fil\n",
    "    def _process_pdf(self, pdf_file: Path) -> None:\n",
    "        print(f\"\\nProcessing PDF: {pdf_file.name}\")\n",
    "        pdf_start = time.time()\n",
    "\n",
    "        try:\n",
    "            doc = fitz.open(str(pdf_file))\n",
    "            for page_num in range(len(doc)):\n",
    "                page_start = time.time()\n",
    "                page = doc.load_page(page_num)\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))\n",
    "                img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(\n",
    "                    (pix.height, pix.width, 3))\n",
    "                img = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Process with face detector\n",
    "                temp_path = self.output_img_dir / f\"temp_{pdf_file.stem}_p{page_num}.png\"\n",
    "                cv2.imwrite(str(temp_path), img)\n",
    "                faces = self.detector.detect_faces(temp_path, is_pdf=True)\n",
    "                temp_path.unlink(missing_ok=True)\n",
    "\n",
    "                page_time = time.time() - page_start\n",
    "                print(f\"Page {page_num+1}: {faces or 0} faces, processed in {page_time:.2f}s\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {pdf_file.name}: {str(e)}\")\n",
    "        \n",
    "        pdf_time = time.time() - pdf_start\n",
    "        print(f\"Finished {pdf_file.name} in {pdf_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing YOLO face detector...\n",
      "Detector initialized in 0.38 seconds\n",
      "\n",
      "\n",
      "==================================================\n",
      "Starting image processing...\n",
      "\n",
      "0: 640x384 (no detections), 44.3ms\n",
      "Speed: 3.2ms preprocess, 44.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 00.jpg | Faces: 0 | Detect: 1.374s | Total: 1.613s\n",
      "Progress: 1/25 | Avg time: 1.617s | Avg faces: 0.0\n",
      "\n",
      "0: 640x384 (no detections), 32.1ms\n",
      "Speed: 1.4ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 01.jpg | Faces: 0 | Detect: 0.038s | Total: 0.280s\n",
      "Progress: 2/25 | Avg time: 0.950s | Avg faces: 0.0\n",
      "\n",
      "0: 640x384 (no detections), 33.5ms\n",
      "Speed: 1.3ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 02.jpg | Faces: 0 | Detect: 0.039s | Total: 0.287s\n",
      "Progress: 3/25 | Avg time: 0.730s | Avg faces: 0.0\n",
      "\n",
      "0: 640x384 (no detections), 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 03.jpg | Faces: 0 | Detect: 0.039s | Total: 0.309s\n",
      "Progress: 4/25 | Avg time: 0.626s | Avg faces: 0.0\n",
      "\n",
      "0: 640x384 1 person, 33.8ms\n",
      "Speed: 1.4ms preprocess, 33.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 04.jpg | Faces: 1 | Detect: 0.039s | Total: 0.317s\n",
      "Progress: 5/25 | Avg time: 0.564s | Avg faces: 0.2\n",
      "\n",
      "0: 640x384 1 person, 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 05.jpg | Faces: 1 | Detect: 0.044s | Total: 0.307s\n",
      "Progress: 6/25 | Avg time: 0.522s | Avg faces: 0.3\n",
      "\n",
      "0: 640x384 (no detections), 36.9ms\n",
      "Speed: 1.7ms preprocess, 36.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 06.jpg | Faces: 0 | Detect: 0.043s | Total: 0.302s\n",
      "Progress: 7/25 | Avg time: 0.491s | Avg faces: 0.3\n",
      "\n",
      "0: 640x384 1 person, 33.3ms\n",
      "Speed: 1.4ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 07.jpg | Faces: 1 | Detect: 0.039s | Total: 0.284s\n",
      "Progress: 8/25 | Avg time: 0.466s | Avg faces: 0.4\n",
      "\n",
      "0: 640x384 (no detections), 30.3ms\n",
      "Speed: 1.5ms preprocess, 30.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 08.jpg | Faces: 0 | Detect: 0.035s | Total: 0.281s\n",
      "Progress: 9/25 | Avg time: 0.445s | Avg faces: 0.3\n",
      "\n",
      "0: 640x384 2 persons, 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 09.jpg | Faces: 2 | Detect: 0.039s | Total: 0.315s\n",
      "Progress: 10/25 | Avg time: 0.433s | Avg faces: 0.5\n",
      "\n",
      "0: 640x384 1 person, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 10.jpg | Faces: 1 | Detect: 0.039s | Total: 0.291s\n",
      "Progress: 11/25 | Avg time: 0.420s | Avg faces: 0.5\n",
      "\n",
      "0: 640x384 1 person, 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 11.jpg | Faces: 1 | Detect: 0.040s | Total: 0.372s\n",
      "Progress: 12/25 | Avg time: 0.416s | Avg faces: 0.6\n",
      "\n",
      "0: 640x384 1 person, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 12.jpg | Faces: 1 | Detect: 0.036s | Total: 0.308s\n",
      "Progress: 13/25 | Avg time: 0.408s | Avg faces: 0.6\n",
      "\n",
      "0: 640x384 1 person, 33.7ms\n",
      "Speed: 1.5ms preprocess, 33.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 13.jpg | Faces: 1 | Detect: 0.041s | Total: 0.288s\n",
      "Progress: 14/25 | Avg time: 0.400s | Avg faces: 0.6\n",
      "\n",
      "0: 640x384 3 persons, 62.0ms\n",
      "Speed: 1.6ms preprocess, 62.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 14.jpg | Faces: 3 | Detect: 0.068s | Total: 0.454s\n",
      "Progress: 15/25 | Avg time: 0.403s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 (no detections), 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 15.jpg | Faces: 0 | Detect: 0.040s | Total: 0.269s\n",
      "Progress: 16/25 | Avg time: 0.395s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 1 person, 32.4ms\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 16.jpg | Faces: 1 | Detect: 0.039s | Total: 0.329s\n",
      "Progress: 17/25 | Avg time: 0.391s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 (no detections), 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 17.jpg | Faces: 0 | Detect: 0.039s | Total: 0.309s\n",
      "Progress: 18/25 | Avg time: 0.387s | Avg faces: 0.7\n",
      "\n",
      "0: 640x384 1 person, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 18.jpg | Faces: 1 | Detect: 0.036s | Total: 0.321s\n",
      "Progress: 19/25 | Avg time: 0.384s | Avg faces: 0.7\n",
      "\n",
      "0: 640x384 1 person, 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 19.jpg | Faces: 1 | Detect: 0.041s | Total: 0.335s\n",
      "Progress: 20/25 | Avg time: 0.381s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 1 person, 36.5ms\n",
      "Speed: 1.6ms preprocess, 36.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 20.jpg | Faces: 1 | Detect: 0.042s | Total: 0.312s\n",
      "Progress: 21/25 | Avg time: 0.378s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 (no detections), 33.1ms\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 21.jpg | Faces: 0 | Detect: 0.039s | Total: 0.305s\n",
      "Progress: 22/25 | Avg time: 0.375s | Avg faces: 0.7\n",
      "\n",
      "0: 640x384 (no detections), 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 22.jpg | Faces: 0 | Detect: 0.040s | Total: 0.299s\n",
      "Progress: 23/25 | Avg time: 0.372s | Avg faces: 0.7\n",
      "\n",
      "0: 640x384 2 persons, 34.9ms\n",
      "Speed: 2.1ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 23.jpg | Faces: 2 | Detect: 0.041s | Total: 0.315s\n",
      "Progress: 24/25 | Avg time: 0.370s | Avg faces: 0.8\n",
      "\n",
      "0: 640x384 1 person, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "YOLO: 24.jpg | Faces: 1 | Detect: 0.041s | Total: 0.306s\n",
      "Progress: 25/25 | Avg time: 0.367s | Avg faces: 0.8\n",
      "\n",
      "==================================================\n",
      "IMAGE PROCESSING SUMMARY\n",
      "Total images processed: 25\n",
      "Images with faces detected: 25\n",
      "Images without faces: 0\n",
      "Total faces detected: 19\n",
      "Total processing time: 9.19 seconds\n",
      "Average time per image: 0.367 seconds\n",
      "Average faces per image: 0.8\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Starting PDF processing...\n",
      "\n",
      "Starting PDF processing...\n",
      "\n",
      "Processing PDF: formato_prueba_famoso_1.pdf\n",
      "\n",
      "0: 640x480 1 person, 52.7ms\n",
      "Speed: 3.2ms preprocess, 52.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "YOLO: temp_formato_prueba_famoso_1_p0.png | Faces: 1 | Detect: 0.060s | Total: 0.160s\n",
      "Page 1: 1 faces, processed in 0.29s\n",
      "Finished formato_prueba_famoso_1.pdf in 0.29 seconds\n",
      "\n",
      "Processing PDF: formato_prueba_famoso_2.pdf\n",
      "\n",
      "0: 640x480 1 person, 46.5ms\n",
      "Speed: 2.8ms preprocess, 46.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "YOLO: temp_formato_prueba_famoso_2_p0.png | Faces: 1 | Detect: 0.055s | Total: 0.164s\n",
      "Page 1: 1 faces, processed in 0.31s\n",
      "Finished formato_prueba_famoso_2.pdf in 0.31 seconds\n",
      "\n",
      "Processing PDF: formato_prueba_famoso_3.pdf\n",
      "\n",
      "0: 640x480 1 person, 37.2ms\n",
      "Speed: 2.3ms preprocess, 37.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "YOLO: temp_formato_prueba_famoso_3_p0.png | Faces: 1 | Detect: 0.044s | Total: 0.146s\n",
      "Page 1: 1 faces, processed in 0.32s\n",
      "Finished formato_prueba_famoso_3.pdf in 0.32 seconds\n",
      "\n",
      "Processing PDF: formato_prueba_famoso_diferente_1.pdf\n",
      "\n",
      "0: 640x480 1 person, 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "YOLO: temp_formato_prueba_famoso_diferente_1_p0.png | Faces: 1 | Detect: 0.047s | Total: 0.143s\n",
      "Page 1: 1 faces, processed in 0.29s\n",
      "Finished formato_prueba_famoso_diferente_1.pdf in 0.29 seconds\n",
      "\n",
      "==================================================\n",
      "PDF PROCESSING SUMMARY\n",
      "Total processing time: 1.23 seconds\n",
      "PDF-only processing time: 1.23 seconds\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "FINAL SUMMARY\n",
      "Total execution time: 10.80 seconds\n",
      "Total images processed: 25\n",
      "Total faces detected: 19\n",
      "Average time per image: 0.367 seconds\n",
      "Average faces per image: 0.8\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize face detector with timing\n",
    "    print(\"Initializing YOLO face detector...\")\n",
    "    init_start = time.perf_counter()\n",
    "    face_detector = FaceDetector()\n",
    "    init_time = time.perf_counter() - init_start\n",
    "    print(f\"Detector initialized in {init_time:.2f} seconds\\n\")\n",
    "    \n",
    "    # Process images with detailed timing and averages\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Starting image processing...\")\n",
    "    img_start = time.perf_counter()\n",
    "    \n",
    "    # Track processing metrics\n",
    "    image_counter = 0\n",
    "    total_faces = 0\n",
    "    total_time = 0.0\n",
    "    max_images = 25\n",
    "    \n",
    "    # Process images with progress tracking\n",
    "    for folder in face_detector.input_dir.iterdir():\n",
    "        if not folder.is_dir():\n",
    "            continue\n",
    "            \n",
    "        for img_path in folder.glob(\"*.jpg\"):\n",
    "            if image_counter >= max_images:\n",
    "                break\n",
    "                \n",
    "            start_time = time.time()\n",
    "            faces_detected = face_detector.detect_faces(img_path)  # Changed from detect_faces_MTCNN\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            total_time += elapsed\n",
    "            if faces_detected is not None:\n",
    "                total_faces += faces_detected\n",
    "            image_counter += 1\n",
    "            \n",
    "            # Display running averages\n",
    "            avg_time = total_time / image_counter\n",
    "            avg_faces = total_faces / image_counter if image_counter > 0 else 0\n",
    "            print(f\"Progress: {image_counter}/{max_images} | \"\n",
    "                  f\"Avg time: {avg_time:.3f}s | \"\n",
    "                  f\"Avg faces: {avg_faces:.1f}\")\n",
    "    \n",
    "    img_elapsed = time.perf_counter() - img_start\n",
    "    \n",
    "    # Image processing summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"IMAGE PROCESSING SUMMARY\")\n",
    "    print(f\"Total images processed: {image_counter}\")\n",
    "    print(f\"Images with faces detected: {image_counter - len(face_detector.no_face_detected)}\")\n",
    "    print(f\"Images without faces: {len(face_detector.no_face_detected)}\")\n",
    "    print(f\"Total faces detected: {total_faces}\")\n",
    "    print(f\"Total processing time: {img_elapsed:.2f} seconds\")\n",
    "    print(f\"Average time per image: {total_time/image_counter:.3f} seconds\")\n",
    "    print(f\"Average faces per image: {total_faces/image_counter:.1f}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Show samples with no faces detected\n",
    "    if face_detector.no_face_detected:\n",
    "        print(f\"Showing {min(3, len(face_detector.no_face_detected))} samples without detected faces...\")\n",
    "        face_detector.show_no_face_samples(sample_size=3)\n",
    "\n",
    "    # Process PDFs with comprehensive timing\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Starting PDF processing...\")\n",
    "    pdf_start = time.perf_counter()\n",
    "    \n",
    "    pdf_processor = PDFProcessor(face_detector)\n",
    "    pdf_time = pdf_processor.process_pdfs()  \n",
    "    pdf_elapsed = time.perf_counter() - pdf_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PDF PROCESSING SUMMARY\")\n",
    "    print(f\"Total processing time: {pdf_elapsed:.2f} seconds\")\n",
    "    if pdf_time > 0:  \n",
    "        print(f\"PDF-only processing time: {pdf_time:.2f} seconds\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(f\"Total execution time: {time.perf_counter() - init_start:.2f} seconds\")\n",
    "    print(f\"Total images processed: {image_counter}\")\n",
    "    print(f\"Total faces detected: {total_faces}\")\n",
    "    print(f\"Average time per image: {total_time/image_counter:.3f} seconds\")\n",
    "    print(f\"Average faces per image: {total_faces/image_counter:.1f}\")\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
